{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import numpy as np\n",
    "import shapely as shp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import rasterio.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = \"..\\\\..\\\\\"\n",
    "cwd_Images_Raw_Dup = cwd + \"\\\\Sentinel-2 Images Raw Duplicate\"\n",
    "cwd_Images_Processed_Dup = cwd + \"\\\\Sentinel-2 Images Processed Duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"USA-LIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA-LIN 1 finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_23988\\1446197830.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA-LIN 2 finished!\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,3,1):\n",
    "\n",
    "    site_Name = site + \" \" + str(i)\n",
    "    cwd_Images_Raw = cwd_Images_Raw_Dup\n",
    "    cwd_Images_Processed = cwd_Images_Processed_Dup\n",
    "    site_Lat = 41.1797\n",
    "    site_Lon = -96.44039\n",
    "    site_Reduced = True\n",
    "    df_4326 = pd.DataFrame({\n",
    "        \"Site\": [site_Name],\n",
    "        \"Latitude\": [site_Lat],\n",
    "        \"Longitude\": [site_Lon]\n",
    "    })\n",
    "    # Create a point shapefile based on the site, using Lon-Lat\n",
    "    gdf_4326 = gpd.GeoDataFrame(\n",
    "        df_4326,\n",
    "        geometry = gpd.points_from_xy(df_4326['Longitude'], df_4326['Latitude']),\n",
    "        crs = \"EPSG:4326\"\n",
    "    )\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"IMG_DATA\" in temp and temp[-3:] == 'jp2' and \"B08\" in temp:\n",
    "                # print(temp)\n",
    "                path_L1C_B08_raw = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"MTD_DS.xml\" in temp:\n",
    "                # print(temp)\n",
    "                path_L1C_xml_DS = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"MTD_TL.xml\" in temp:\n",
    "                # print(temp)\n",
    "                path_L1C_xml_TL = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B04\" in temp :\n",
    "                path_L2A_B04_raw = temp\n",
    "            if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B08\" in temp :\n",
    "                path_L2A_B08_raw = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"MTD_DS.xml\" in temp:\n",
    "                # print(temp)\n",
    "                path_L2A_xml_DS = temp\n",
    "    image_L1C_B08 = rio.open(path_L1C_B08_raw)\n",
    "    image_L2A_B04 = rio.open(path_L2A_B04_raw)\n",
    "    image_L2A_B08 = rio.open(path_L2A_B08_raw)\n",
    "    values_L1C_B08 = image_L1C_B08.read(1)\n",
    "    values_L2A_B04 = image_L2A_B04.read(1)\n",
    "    values_L2A_B08 = image_L2A_B08.read(1)\n",
    "    crs_L1C = image_L1C_B08.crs.data[\"init\"].split(\":\")[1]\n",
    "    crs_L2A = image_L2A_B04.crs.data[\"init\"].split(\":\")[1]\n",
    "    # print(\"The EPSG of L1C is \" + crs_L1C)\n",
    "    # print(\"The EPSG of L2A is \" + crs_L2A)\n",
    "    # In the case that L1C and L2A have different crs, give an error. But this shouldn't happen. \n",
    "    if crs_L2A != crs_L1C:\n",
    "        raise SystemExit(\"Stop right there!\")\n",
    "    crs_Final = 'EPSG:' + crs_L1C\n",
    "    gdf_New = gdf_4326.copy()\n",
    "    gdf_New = gdf_New.to_crs(crs_Final)\n",
    "    site_x = gdf_New.geometry.x.values[0]\n",
    "    site_y = gdf_New.geometry.y.values[0]\n",
    "    site_row, site_col = image_L2A_B08.index(site_x, site_y)\n",
    "    site_pixel_x, site_pixel_y = image_L2A_B08.xy(site_row, site_col)\n",
    "    # Get the coordinates of the four corners\n",
    "    # 10m\n",
    "    site_x_left_10m = site_pixel_x - 5\n",
    "    site_x_right_10m = site_pixel_x + 5\n",
    "    site_y_top_10m = site_pixel_y + 5\n",
    "    site_y_bottom_10m = site_pixel_y - 5\n",
    "    # 30m\n",
    "    site_x_left_30m = site_pixel_x - 15\n",
    "    site_x_right_30m = site_pixel_x + 15\n",
    "    site_y_top_30m = site_pixel_y + 15\n",
    "    site_y_bottom_30m = site_pixel_y - 15\n",
    "    # 100m\n",
    "    site_x_left_100m = site_pixel_x - 55\n",
    "    site_x_right_100m = site_pixel_x + 55\n",
    "    site_y_top_100m = site_pixel_y + 55\n",
    "    site_y_bottom_100m = site_pixel_y - 55\n",
    "    # 100 * 1.5 = 150m\n",
    "    site_x_left_150m = site_pixel_x - 75\n",
    "    site_x_right_150m = site_pixel_x + 75\n",
    "    site_y_top_150m = site_pixel_y + 75\n",
    "    site_y_bottom_150m = site_pixel_y - 75\n",
    "    # 300m\n",
    "    site_x_left_300m = site_pixel_x - 155\n",
    "    site_x_right_300m = site_pixel_x + 155\n",
    "    site_y_top_300m = site_pixel_y + 155\n",
    "    site_y_bottom_300m = site_pixel_y - 155\n",
    "    # 300 * 1.5 = 450m\n",
    "    site_x_left_450m = site_pixel_x - 225\n",
    "    site_x_right_450m = site_pixel_x + 225\n",
    "    site_y_top_450m = site_pixel_y + 225\n",
    "    site_y_bottom_450m = site_pixel_y - 225\n",
    "    if site_Reduced:\n",
    "        # 600m\n",
    "        site_x_left_600m = site_pixel_x - 305\n",
    "        site_x_right_600m = site_pixel_x + 305\n",
    "        site_y_top_600m = site_pixel_y + 305\n",
    "        site_y_bottom_600m = site_pixel_y - 305\n",
    "    # 900m\n",
    "    site_x_left_900m = site_pixel_x - 455\n",
    "    site_x_right_900m = site_pixel_x + 455\n",
    "    site_y_top_900m = site_pixel_y + 455\n",
    "    site_y_bottom_900m = site_pixel_y - 455\n",
    "    # 900 * 1.5 = 1350m\n",
    "    site_x_left_1350m = site_pixel_x - 675\n",
    "    site_x_right_1350m = site_pixel_x + 675\n",
    "    site_y_top_1350m = site_pixel_y + 675\n",
    "    site_y_bottom_1350m = site_pixel_y - 675\n",
    "    # 1200m\n",
    "    site_x_left_1200m = site_pixel_x - 605\n",
    "    site_x_right_1200m = site_pixel_x + 605\n",
    "    site_y_top_1200m = site_pixel_y + 605\n",
    "    site_y_bottom_1200m = site_pixel_y - 605\n",
    "    # 1800m\n",
    "    site_x_left_1800m = site_pixel_x - 905\n",
    "    site_x_right_1800m = site_pixel_x + 905\n",
    "    site_y_top_1800m = site_pixel_y + 905\n",
    "    site_y_bottom_1800m = site_pixel_y - 905\n",
    "    # 2500m\n",
    "    site_x_left_2500m = site_pixel_x - 1255\n",
    "    site_x_right_2500m = site_pixel_x + 1255\n",
    "    site_y_top_2500m = site_pixel_y + 1255\n",
    "    site_y_bottom_2500m = site_pixel_y - 1255\n",
    "    # Now we need to form squares shapefile, which will be the internal area of which we will evaluate the spatial representativeness. \n",
    "    shp_10m = shp.box(site_x_left_10m, site_y_bottom_10m, site_x_right_10m, site_y_top_10m)\n",
    "    gdf_10m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_10m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_30m = shp.box(site_x_left_30m, site_y_bottom_30m, site_x_right_30m, site_y_top_30m)\n",
    "    gdf_30m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_30m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_100m = shp.box(site_x_left_100m, site_y_bottom_100m, site_x_right_100m, site_y_top_100m)\n",
    "    gdf_100m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_100m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_150m = shp.box(site_x_left_150m, site_y_bottom_150m, site_x_right_150m, site_y_top_150m)\n",
    "    gdf_150m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_150m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_300m = shp.box(site_x_left_300m, site_y_bottom_300m, site_x_right_300m, site_y_top_300m)\n",
    "    gdf_300m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_300m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_450m = shp.box(site_x_left_450m, site_y_bottom_450m, site_x_right_450m, site_y_top_450m)\n",
    "    gdf_450m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_450m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    if site_Reduced:\n",
    "        shp_600m = shp.box(site_x_left_600m, site_y_bottom_600m, site_x_right_600m, site_y_top_600m)\n",
    "        gdf_600m = gpd.GeoDataFrame(\n",
    "            pd.DataFrame({\"0\": [\"0\"]}),\n",
    "            geometry=[shp_600m],\n",
    "            crs = crs_Final\n",
    "        )\n",
    "    shp_900m = shp.box(site_x_left_900m, site_y_bottom_900m, site_x_right_900m, site_y_top_900m)\n",
    "    gdf_900m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_900m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_1350m = shp.box(site_x_left_1350m, site_y_bottom_1350m, site_x_right_1350m, site_y_top_1350m)\n",
    "    gdf_1350m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_1350m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_1200m = shp.box(site_x_left_1200m, site_y_bottom_1200m, site_x_right_1200m, site_y_top_1200m)\n",
    "    gdf_1200m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_1200m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_1800m = shp.box(site_x_left_1800m, site_y_bottom_1800m, site_x_right_1800m, site_y_top_1800m)\n",
    "    gdf_1800m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_1800m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_2500m = shp.box(site_x_left_2500m, site_y_bottom_2500m, site_x_right_2500m, site_y_top_2500m)\n",
    "    gdf_2500m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_2500m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    # Read the DS xml file of L2A\n",
    "    with open(path_L2A_xml_DS, 'r') as f:\n",
    "        data = f.read()\n",
    "    BS_L2A_dS = BeautifulSoup(data, \"xml\")\n",
    "    # Get the quantification value! \n",
    "    quantification_L2A = int(BS_L2A_dS.find(\"BOA_QUANTIFICATION_VALUE\").text)\n",
    "    # Get the radiometric offset!\n",
    "    offset_L2A_B04 = int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"3\"}).text)\n",
    "    offset_L2A_B08 = int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"7\"}).text)\n",
    "    NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
    "    src = image_L2A_B04\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"dtype\": 'float64'\n",
    "    })\n",
    "    with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NDVI.tif\", 'w', **out_meta) as dest:\n",
    "        dest.write(NDVI, 1)\n",
    "    # Read the DS xml file of L1C\n",
    "    with open(path_L1C_xml_DS, 'r') as f:\n",
    "        data = f.read()\n",
    "    BS_L1C_dS = BeautifulSoup(data, \"xml\")\n",
    "    # Get the quantification value! \n",
    "    quantification_L1C = int(BS_L1C_dS.find(\"QUANTIFICATION_VALUE\").text)\n",
    "    # Get the radiometric offset!\n",
    "    offset_L1C = int(BS_L1C_dS.find(\"RADIO_ADD_OFFSET\", {\"band_id\": \"7\"}).text)\n",
    "    # Get the U\n",
    "    U_L1C = float(BS_L1C_dS.find(\"U\").text)\n",
    "    # Get the solar irradiance\n",
    "    SolarIrr = float(BS_L1C_dS.find(\"SOLAR_IRRADIANCE\", {\"bandId\": \"7\"}).text)\n",
    "    # Read the TL xml file of L1C\n",
    "    with open(path_L1C_xml_TL, 'r') as f:\n",
    "        data = f.read()\n",
    "    BS_L1C_dS = BeautifulSoup(data, \"xml\")\n",
    "    # Get the sun zenith angle! There should be a 23 x 23 arrays in the xml. Now we save each row as an array and keep all these arrays into a list\n",
    "    list_SunZenith = []\n",
    "    for row in BS_L1C_dS.find(\"Sun_Angles_Grid\").find(\"Zenith\").find_all(\"VALUES\"):\n",
    "        temp_List = row.text.split(\" \")\n",
    "        temp_Arr = np.array(temp_List)\n",
    "        temp_Arr = temp_Arr.astype(float)\n",
    "        list_SunZenith.append(temp_Arr)\n",
    "    # Now we stack these nested-in-list arrays into a 2d array\n",
    "    index = 0\n",
    "    for arr in list_SunZenith:\n",
    "        if index == 0:\n",
    "            arr_SunZenith = arr\n",
    "        else:\n",
    "            arr_SunZenith = np.vstack((arr_SunZenith, arr))\n",
    "        index = index + 1\n",
    "    # Get the shape of L1C image, which should be (10980, 10980)\n",
    "    shape_L1C = values_L1C_B08.shape\n",
    "    # Repeat each element of sun zenith angle array, in both axies. The final array should have a shape of (11500, 11500)\n",
    "    arr_SunZenith_Repeat = np.repeat(arr_SunZenith, 500, axis = 1)\n",
    "    arr_SunZenith_Repeat = np.repeat(arr_SunZenith_Repeat, 500, axis = 0)\n",
    "    # Index only the first 10980 of each dimension\n",
    "    arr_SunZenith_Assigned = arr_SunZenith_Repeat[0:shape_L1C[0], 0:shape_L1C[1]]\n",
    "    # radiance = reflectance * cos(radians(SunZenithAngle)) * solarIrradiance * U / pi\n",
    "    radiance = (values_L1C_B08 + offset_L1C).astype(float)  * np.cos(np.radians(arr_SunZenith_Assigned)) * SolarIrr / quantification_L1C / (math.pi * (1 / U_L1C))\n",
    "    NIRv = NDVI * radiance\n",
    "    src = image_L1C_B08\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"dtype\": 'float64'\n",
    "    })\n",
    "    with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\", 'w', **out_meta) as dest:\n",
    "        dest.write(NIRv, 1)\n",
    "    list_Distance = ['10m','30m','100m','150m','300m','450m','900m','1350m','1200m','1800m','2500m']\n",
    "    list_GDF = [gdf_10m,gdf_30m,gdf_100m,gdf_150m,gdf_300m,gdf_450m,gdf_900m,gdf_1350m,gdf_1200m,gdf_1800m,gdf_2500m]\n",
    "    for index in range(len(list_Distance)):\n",
    "        temp_Distance = list_Distance[index]\n",
    "        temp_GDF = list_GDF[index]\n",
    "        src = rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\")\n",
    "        out_image, out_transform = rio.mask.mask(src, temp_GDF.geometry, crop=True)\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform})\n",
    "\n",
    "        with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv \" + temp_Distance + \".tif\", \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "    for i in range(len(list_Distance)):\n",
    "        list_GDF[i].to_file(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\\" + list_Distance[i] + \".shp\")\n",
    "    if site_Reduced:\n",
    "        src = rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\")\n",
    "        out_image, out_transform = rio.mask.mask(src, gdf_600m.geometry, crop=True)\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform})\n",
    "\n",
    "        with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv 600m.tif\", \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "        gdf_600m.to_file(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\600m.shp\")\n",
    "    print(site_Name + \" finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DISC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
