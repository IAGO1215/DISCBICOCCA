{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import numpy as np\n",
    "import shapely as shp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import rasterio.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the working directory (absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\DISC\"\n",
    "cwd_Images_Raw = cwd + \"\\\\Sentinel-2 Images Raw\"\n",
    "cwd_Images_Processed = cwd + \"\\\\Sentinel-2 Images Processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the site name and its latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site Name\n",
    "site_Name = \"Tapajos KM67 Mature Forest site\"\n",
    "site_Name_New = \"Tapajos KM67 Mature Forest site\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the coordinate based on the name of the site in our .csv file\n",
    "df_Site = pd.read_csv(cwd + \"//Site.csv\")\n",
    "for i in range(df_Site.shape[0]):\n",
    "    if df_Site.loc[i,\"Site\"] == site_Name_New:\n",
    "        site_Lat = df_Site.loc[i,\"Latitude\"]\n",
    "        site_Lon = df_Site.loc[i,\"Longitude\"]\n",
    "# print(f\"The latitude of the site is {site_Lat:.4f} and the longitude is {site_Lon:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a geodataframe of the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tapajos KM67 Mature Forest site</td>\n",
       "      <td>-2.8567</td>\n",
       "      <td>-54.9589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Site  Latitude  Longitude\n",
       "0  Tapajos KM67 Mature Forest site   -2.8567   -54.9589"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4326 = pd.DataFrame({\n",
    "    \"Site\": [site_Name_New],\n",
    "    \"Latitude\": [site_Lat],\n",
    "    \"Longitude\": [site_Lon]\n",
    "})\n",
    "df_4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tapajos KM67 Mature Forest site</td>\n",
       "      <td>-2.8567</td>\n",
       "      <td>-54.9589</td>\n",
       "      <td>POINT (-54.9589 -2.8567)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Site  Latitude  Longitude  \\\n",
       "0  Tapajos KM67 Mature Forest site   -2.8567   -54.9589   \n",
       "\n",
       "                   geometry  \n",
       "0  POINT (-54.9589 -2.8567)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a point shapefile based on the site, using Lon-Lat\n",
    "gdf_4326 = gpd.GeoDataFrame(\n",
    "    df_4326,\n",
    "    geometry = gpd.points_from_xy(df_4326['Longitude'], df_4326['Latitude']),\n",
    "    crs = \"EPSG:4326\"\n",
    ")\n",
    "gdf_4326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the paths to the raw L1C rasters\n",
    "We only need the B08 (NIR) image file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\m1865\\\\Desktop\\\\DISC\\\\Sentinel-2 Images Raw\\\\Tapajos KM67 Mature Forest site\\\\L1C\\\\S2B_MSIL1C_20230819T135709_N0509_R067_T21MYS_20230819T172029.SAFE\\\\GRANULE\\\\L1C_T21MYS_A033698_20230819T135707\\\\IMG_DATA\\\\T21MYS_20230819T135709_B08.jp2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "    for name in files:\n",
    "        temp = os.path.join(path, name)\n",
    "        if \"IMG_DATA\" in temp and temp[-3:] == 'jp2' and \"B08\" in temp:\n",
    "            # print(temp)\n",
    "            path_L1C_B08_raw = temp\n",
    "path_L1C_B08_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the path to the XML file \"MTD_DS\" of L1C raster, where there are values of \"U\", \"Solar Irradiance\", \"Quantification Value\" and \"Radiometric Offset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\m1865\\\\Desktop\\\\DISC\\\\Sentinel-2 Images Raw\\\\Tapajos KM67 Mature Forest site\\\\L1C\\\\S2B_MSIL1C_20230819T135709_N0509_R067_T21MYS_20230819T172029.SAFE\\\\DATASTRIP\\\\DS_2BPS_20230819T172029_S20230819T135707\\\\MTD_DS.xml'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "    for name in files:\n",
    "        temp = os.path.join(path, name)\n",
    "        if \"MTD_DS.xml\" in temp:\n",
    "            # print(temp)\n",
    "            path_L1C_xml_DS = temp\n",
    "path_L1C_xml_DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the path to the XML file \"MTD_TL\" of L1C raster, where there are values (matrices) of \"Solar Zenith Angle\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\m1865\\\\Desktop\\\\DISC\\\\Sentinel-2 Images Raw\\\\Tapajos KM67 Mature Forest site\\\\L1C\\\\S2B_MSIL1C_20230819T135709_N0509_R067_T21MYS_20230819T172029.SAFE\\\\GRANULE\\\\L1C_T21MYS_A033698_20230819T135707\\\\MTD_TL.xml'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "    for name in files:\n",
    "        temp = os.path.join(path, name)\n",
    "        if \"MTD_TL.xml\" in temp:\n",
    "            # print(temp)\n",
    "            path_L1C_xml_TL = temp\n",
    "path_L1C_xml_TL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the paths to the raw L2A rasters\n",
    "We get the paths to the B04 (Red) band and B08 (NIR) band. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path to B04 is c:\\Users\\m1865\\Desktop\\DISC\\Sentinel-2 Images Raw\\Tapajos KM67 Mature Forest site\\L2A\\S2B_MSIL2A_20230819T135709_N0509_R067_T21MYS_20230819T181035.SAFE\\GRANULE\\L2A_T21MYS_A033698_20230819T135707\\IMG_DATA\\R10m\\T21MYS_20230819T135709_B04_10m.jp2\n",
      "The path to B08 is c:\\Users\\m1865\\Desktop\\DISC\\Sentinel-2 Images Raw\\Tapajos KM67 Mature Forest site\\L2A\\S2B_MSIL2A_20230819T135709_N0509_R067_T21MYS_20230819T181035.SAFE\\GRANULE\\L2A_T21MYS_A033698_20230819T135707\\IMG_DATA\\R10m\\T21MYS_20230819T135709_B08_10m.jp2\n"
     ]
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "    for name in files:\n",
    "        temp = os.path.join(path, name)\n",
    "        if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B04\" in temp :\n",
    "            path_L2A_B04_raw = temp\n",
    "        if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B08\" in temp :\n",
    "            path_L2A_B08_raw = temp\n",
    "print(\"The path to B04 is \" + path_L2A_B04_raw)\n",
    "print(\"The path to B08 is \" + path_L2A_B08_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the path to the XML file \"MTD_DS\" of L1C raster, where there are values of \"Quantification Value\" and \"Radiometric Offset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\m1865\\\\Desktop\\\\DISC\\\\Sentinel-2 Images Raw\\\\Tapajos KM67 Mature Forest site\\\\L2A\\\\S2B_MSIL2A_20230819T135709_N0509_R067_T21MYS_20230819T181035.SAFE\\\\DATASTRIP\\\\DS_2BPS_20230819T181035_S20230819T135707\\\\MTD_DS.xml'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "    for name in files:\n",
    "        temp = os.path.join(path, name)\n",
    "        if \"MTD_DS.xml\" in temp:\n",
    "            # print(temp)\n",
    "            path_L2A_xml_DS = temp\n",
    "path_L2A_xml_DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now read the path into image with rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rasterio.io.DatasetReader"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_L1C_B08 = rio.open(path_L1C_B08_raw)\n",
    "image_L2A_B04 = rio.open(path_L2A_B04_raw)\n",
    "image_L2A_B08 = rio.open(path_L2A_B08_raw)\n",
    "type(image_L2A_B08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And then read the values of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_L1C_B08 = image_L1C_B08.read(1)\n",
    "values_L2A_B04 = image_L2A_B04.read(1)\n",
    "values_L2A_B08 = image_L2A_B08.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now check the crs of the Sentinel-2 images, and convert our site geodataframe to that crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EPSG of L1C is 32721\n",
      "The EPSG of L2A is 32721\n",
      "The final crs is EPSG:32721\n"
     ]
    }
   ],
   "source": [
    "crs_L1C = image_L1C_B08.crs.data[\"init\"].split(\":\")[1]\n",
    "crs_L2A = image_L2A_B04.crs.data[\"init\"].split(\":\")[1]\n",
    "print(\"The EPSG of L1C is \" + crs_L1C)\n",
    "print(\"The EPSG of L2A is \" + crs_L2A)\n",
    "# In the case that L1C and L2A have different crs, give an error. But this shouldn't happen. \n",
    "if crs_L2A != crs_L1C:\n",
    "    raise SystemExit(\"Stop right there!\")\n",
    "crs_Final = 'EPSG:' + crs_L1C\n",
    "print(\"The final crs is \" + crs_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tapajos KM67 Mature Forest site</td>\n",
       "      <td>-2.8567</td>\n",
       "      <td>-54.9589</td>\n",
       "      <td>POINT (726891.047 9684044.712)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Site  Latitude  Longitude  \\\n",
       "0  Tapajos KM67 Mature Forest site   -2.8567   -54.9589   \n",
       "\n",
       "                         geometry  \n",
       "0  POINT (726891.047 9684044.712)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Lon-Lat to UTM coordinates!\n",
    "# Attention that the CRS in USA for meter unit is 32618!!! Not 32632!!! \n",
    "gdf_New = gdf_4326.copy()\n",
    "gdf_New = gdf_New.to_crs(crs_Final)\n",
    "gdf_New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we assign the site location to a pixel in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site X, Y: 726891.0466288019,9684044.711766005\n"
     ]
    }
   ],
   "source": [
    "# First we retrieve the x, y coordinate of our site\n",
    "site_x = gdf_New.geometry.x.values[0]\n",
    "site_y = gdf_New.geometry.y.values[0]\n",
    "print(\"Site X, Y: \" + str(site_x) + \",\" + str(site_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site falls on the pixel: 1595, 2693\n"
     ]
    }
   ],
   "source": [
    "# Then we get the row, col of our site in the raster, so that we know the pixel the site belongs to\n",
    "site_row, site_col = image_L2A_B08.index(site_x, site_y)\n",
    "print(\"Site falls on the pixel: \" + str(site_row) + \", \" + str(site_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spatial coordinates of the (center) pixel which the site falls on is: 726895.0, 9684045.0\n"
     ]
    }
   ],
   "source": [
    "# Now we get the spatial coordinates of that pixel (coordinates of its center)\n",
    "site_pixel_x, site_pixel_y = image_L2A_B08.xy(site_row, site_col)\n",
    "print(\"The spatial coordinates of the (center) pixel which the site falls on is: \" + str(site_pixel_x) + \", \" + str(site_pixel_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we create four squares centered at our site pixel! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coordinates of the four corners\n",
    "# 10m\n",
    "site_x_left_10m = site_pixel_x - 5\n",
    "site_x_right_10m = site_pixel_x + 5\n",
    "site_y_top_10m = site_pixel_y + 5\n",
    "site_y_bottom_10m = site_pixel_y - 5\n",
    "# 30m\n",
    "site_x_left_30m = site_pixel_x - 15\n",
    "site_x_right_30m = site_pixel_x + 15\n",
    "site_y_top_30m = site_pixel_y + 15\n",
    "site_y_bottom_30m = site_pixel_y - 15\n",
    "# 100m\n",
    "site_x_left_100m = site_pixel_x - 55\n",
    "site_x_right_100m = site_pixel_x + 55\n",
    "site_y_top_100m = site_pixel_y + 55\n",
    "site_y_bottom_100m = site_pixel_y - 55\n",
    "# 100 * 1.5 = 150m\n",
    "site_x_left_150m = site_pixel_x - 75\n",
    "site_x_right_150m = site_pixel_x + 75\n",
    "site_y_top_150m = site_pixel_y + 75\n",
    "site_y_bottom_150m = site_pixel_y - 75\n",
    "# 300m\n",
    "site_x_left_300m = site_pixel_x - 155\n",
    "site_x_right_300m = site_pixel_x + 155\n",
    "site_y_top_300m = site_pixel_y + 155\n",
    "site_y_bottom_300m = site_pixel_y - 155\n",
    "# 300 * 1.5 = 450m\n",
    "site_x_left_450m = site_pixel_x - 225\n",
    "site_x_right_450m = site_pixel_x + 225\n",
    "site_y_top_450m = site_pixel_y + 225\n",
    "site_y_bottom_450m = site_pixel_y - 225\n",
    "# 600m\n",
    "site_x_left_600m = site_pixel_x - 305\n",
    "site_x_right_600m = site_pixel_x + 305\n",
    "site_y_top_600m = site_pixel_y + 305\n",
    "site_y_bottom_600m = site_pixel_y - 305\n",
    "# 900m\n",
    "site_x_left_900m = site_pixel_x - 455\n",
    "site_x_right_900m = site_pixel_x + 455\n",
    "site_y_top_900m = site_pixel_y + 455\n",
    "site_y_bottom_900m = site_pixel_y - 455\n",
    "# 900 * 1.5 = 1350m\n",
    "site_x_left_1350m = site_pixel_x - 675\n",
    "site_x_right_1350m = site_pixel_x + 675\n",
    "site_y_top_1350m = site_pixel_y + 675\n",
    "site_y_bottom_1350m = site_pixel_y - 675\n",
    "# 1200m\n",
    "site_x_left_1200m = site_pixel_x - 605\n",
    "site_x_right_1200m = site_pixel_x + 605\n",
    "site_y_top_1200m = site_pixel_y + 605\n",
    "site_y_bottom_1200m = site_pixel_y - 605\n",
    "# 1800m\n",
    "site_x_left_1800m = site_pixel_x - 905\n",
    "site_x_right_1800m = site_pixel_x + 905\n",
    "site_y_top_1800m = site_pixel_y + 905\n",
    "site_y_bottom_1800m = site_pixel_y - 905\n",
    "# 2500m\n",
    "site_x_left_2500m = site_pixel_x - 1255\n",
    "site_x_right_2500m = site_pixel_x + 1255\n",
    "site_y_top_2500m = site_pixel_y + 1255\n",
    "site_y_bottom_2500m = site_pixel_y - 1255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to form squares shapefile, which will be the internal area of which we will evaluate the spatial representativeness. \n",
    "shp_10m = shp.box(site_x_left_10m, site_y_bottom_10m, site_x_right_10m, site_y_top_10m)\n",
    "gdf_10m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_10m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_30m = shp.box(site_x_left_30m, site_y_bottom_30m, site_x_right_30m, site_y_top_30m)\n",
    "gdf_30m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_30m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_100m = shp.box(site_x_left_100m, site_y_bottom_100m, site_x_right_100m, site_y_top_100m)\n",
    "gdf_100m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_100m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_150m = shp.box(site_x_left_150m, site_y_bottom_150m, site_x_right_150m, site_y_top_150m)\n",
    "gdf_150m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_150m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_300m = shp.box(site_x_left_300m, site_y_bottom_300m, site_x_right_300m, site_y_top_300m)\n",
    "gdf_300m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_300m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_450m = shp.box(site_x_left_450m, site_y_bottom_450m, site_x_right_450m, site_y_top_450m)\n",
    "gdf_450m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_450m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_600m = shp.box(site_x_left_600m, site_y_bottom_600m, site_x_right_600m, site_y_top_600m)\n",
    "gdf_600m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_600m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_900m = shp.box(site_x_left_900m, site_y_bottom_900m, site_x_right_900m, site_y_top_900m)\n",
    "gdf_900m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_900m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_1350m = shp.box(site_x_left_1350m, site_y_bottom_1350m, site_x_right_1350m, site_y_top_1350m)\n",
    "gdf_1350m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_1350m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_1200m = shp.box(site_x_left_1200m, site_y_bottom_1200m, site_x_right_1200m, site_y_top_1200m)\n",
    "gdf_1200m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_1200m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_1800m = shp.box(site_x_left_1800m, site_y_bottom_1800m, site_x_right_1800m, site_y_top_1800m)\n",
    "gdf_1800m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_1800m],\n",
    "    crs = crs_Final\n",
    ")\n",
    "shp_2500m = shp.box(site_x_left_2500m, site_y_bottom_2500m, site_x_right_2500m, site_y_top_2500m)\n",
    "gdf_2500m = gpd.GeoDataFrame(\n",
    "    pd.DataFrame({\"0\": [\"0\"]}),\n",
    "    geometry=[shp_2500m],\n",
    "    crs = crs_Final\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NDVI based on the L2A image! This calculation is performed on the entire image, and the image cropping will be performed later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DS xml file of L2A\n",
    "with open(path_L2A_xml_DS, 'r') as f:\n",
    "    data = f.read()\n",
    "BS_L2A_dS = BeautifulSoup(data, \"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the quantification value! \n",
    "quantification_L2A = int(BS_L2A_dS.find(\"BOA_QUANTIFICATION_VALUE\").text)\n",
    "# Get the radiometric offset!\n",
    "offset_L2A_B04 = abs(int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"3\"}).text))\n",
    "offset_L2A_B08 = abs(int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"7\"}).text))\n",
    "offset_L2A_B08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46726047,  0.46914021,  0.47102313, ...,  0.40375123,\n",
       "         0.45275035,  0.49636225],\n",
       "       [ 0.46319393,  0.46362649,  0.4695392 , ...,  0.46406268,\n",
       "         0.44605065,  0.41604456],\n",
       "       [ 0.45807089,  0.47063789,  0.47569816, ...,  0.41875761,\n",
       "         0.3439582 ,  0.30219992],\n",
       "       ...,\n",
       "       [-0.0051619 , -0.00775558, -0.00634548, ...,  0.15353371,\n",
       "         0.14285714,  0.11974954],\n",
       "       [-0.005145  , -0.01148886, -0.0112782 , ...,  0.14784876,\n",
       "         0.11643657,  0.11859059],\n",
       "       [-0.00611189, -0.01129412, -0.00636042, ...,  0.12797927,\n",
       "         0.11227978,  0.11081864]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate NDVI of L2A! \n",
    "NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
    "NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = image_L2A_B04\n",
    "out_meta = src.meta\n",
    "out_meta.update({\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"dtype\": 'float64'\n",
    "})\n",
    "with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name_New + \"\\\\NDVI No Offset.tif\", 'w', **out_meta) as dest:\n",
    "    dest.write(NDVI, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse XML file of L1C images! We start with MTD_DS.xml which is easier to parse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DS xml file of L1C\n",
    "with open(path_L1C_xml_DS, 'r') as f:\n",
    "    data = f.read()\n",
    "BS_L1C_dS = BeautifulSoup(data, \"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the quantification value! \n",
    "quantification_L1C = int(BS_L1C_dS.find(\"QUANTIFICATION_VALUE\").text)\n",
    "# Get the radiometric offset!\n",
    "offset_L1C = int(BS_L1C_dS.find(\"RADIO_ADD_OFFSET\", {\"band_id\": \"7\"}).text)\n",
    "# Get the U\n",
    "U_L1C = float(BS_L1C_dS.find(\"U\").text)\n",
    "# Get the solar irradiance\n",
    "SolarIrr = float(BS_L1C_dS.find(\"SOLAR_IRRADIANCE\", {\"bandId\": \"7\"}).text)\n",
    "quantification_L1C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we parse MTD_TL.xml to get the sun zenith angle! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the TL xml file of L1C\n",
    "with open(path_L1C_xml_TL, 'r') as f:\n",
    "    data = f.read()\n",
    "BS_L1C_dS = BeautifulSoup(data, \"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 23)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sun zenith angle! There should be a 23 x 23 arrays in the xml. Now we save each row as an array and keep all these arrays into a list\n",
    "list_SunZenith = []\n",
    "for row in BS_L1C_dS.find(\"Sun_Angles_Grid\").find(\"Zenith\").find_all(\"VALUES\"):\n",
    "    temp_List = row.text.split(\" \")\n",
    "    temp_Arr = np.array(temp_List)\n",
    "    temp_Arr = temp_Arr.astype(float)\n",
    "    list_SunZenith.append(temp_Arr)\n",
    "# Now we stack these nested-in-list arrays into a 2d array\n",
    "index = 0\n",
    "for arr in list_SunZenith:\n",
    "    if index == 0:\n",
    "        arr_SunZenith = arr\n",
    "    else:\n",
    "        arr_SunZenith = np.vstack((arr_SunZenith, arr))\n",
    "    index = index + 1\n",
    "arr_SunZenith.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now since that we have retrieved the sun zenith angle, we have to assign that value to each pixel, due to the different spatial resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 10980)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of L1C image, which should be (10980, 10980)\n",
    "shape_L1C = values_L1C_B08.shape\n",
    "shape_L1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11500, 11500)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat each element of sun zenith angle array, in both axies. The final array should have a shape of (11500, 11500)\n",
    "arr_SunZenith_Repeat = np.repeat(arr_SunZenith, 500, axis = 1)\n",
    "arr_SunZenith_Repeat = np.repeat(arr_SunZenith_Repeat, 500, axis = 0)\n",
    "arr_SunZenith_Repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 10980)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index only the first 10980 of each dimension\n",
    "arr_SunZenith_Assigned = arr_SunZenith_Repeat[0:shape_L1C[0], 0:shape_L1C[1]]\n",
    "arr_SunZenith_Assigned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, finally we can calculate the radiance of L1C from reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_L1C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101.83195164, 105.34169366, 108.30767283, ...,  76.25307626,\n",
       "         79.48098245,  77.79253921],\n",
       "       [111.27365201, 115.37658986, 116.71128049, ...,  84.09937131,\n",
       "         79.92792331,  82.93235907],\n",
       "       [118.14483709, 121.72872859, 121.13553276, ...,  88.07217893,\n",
       "         85.16706336,  83.6772605 ],\n",
       "       ...,\n",
       "       [ 77.76778749,  72.93391213,  60.13541313, ..., 154.32550846,\n",
       "        165.24452879, 170.55308475],\n",
       "       [ 63.59175924,  62.41459788,  47.23673018, ..., 161.57130997,\n",
       "        171.08142445, 173.37089645],\n",
       "       [ 65.79580603,  46.61058052,  32.3844603 , ..., 177.82404529,\n",
       "        184.18928064, 185.49755036]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# radiance = reflectance * cos(radians(SunZenithAngle)) * solarIrradiance * U / pi\n",
    "radiance = (values_L1C_B08 + offset_L1C).astype(float)  * np.cos(np.radians(arr_SunZenith_Assigned)) * SolarIrr / quantification_L1C / (math.pi * (1 / U_L1C))\n",
    "radiance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we finally calculate the NDVI * Rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 19.89549113,  17.86601263,  19.52708846, ...,  58.65621251,\n",
       "         61.22777816,  57.71984828],\n",
       "       [ 21.92070068,  19.56917425,  20.35542929, ...,  70.02182106,\n",
       "         63.31177721,  65.27897135],\n",
       "       [ 19.18223429,  18.24681147,  18.9415578 , ...,  76.77301326,\n",
       "         71.08057799,  67.10920584],\n",
       "       ...,\n",
       "       [ 69.45796396,  57.86632997,  30.17130587, ..., -11.8482899 ,\n",
       "        -12.88389139, -11.21753741],\n",
       "       [ 56.11274108,  39.02194859,  13.82203332, ..., -13.05299119,\n",
       "        -12.96393403, -12.30798983],\n",
       "       [ 57.83503095,  30.6217603 ,   9.87611201, ..., -11.94028763,\n",
       "        -12.52618869, -14.02657772]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIRv = NDVI * radiance\n",
    "NIRv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = image_L1C_B08\n",
    "out_meta = src.meta\n",
    "out_meta.update({\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"dtype\": 'float64'\n",
    "})\n",
    "with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name_New + \"\\\\NIRv.tif\", 'w', **out_meta) as dest:\n",
    "    dest.write(NIRv, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Distance = ['10m','30m','100m','150m','300m','450m','600m','900m','1350m','1200m','1800m','2500m']\n",
    "list_GDF = [gdf_10m,gdf_30m,gdf_100m,gdf_150m,gdf_300m,gdf_450m,gdf_600m,gdf_900m,gdf_1350m,gdf_1200m,gdf_1800m,gdf_2500m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(list_Distance)):\n",
    "    temp_Distance = list_Distance[index]\n",
    "    temp_GDF = list_GDF[index]\n",
    "    src = rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\")\n",
    "    out_image, out_transform = rio.mask.mask(src, temp_GDF.geometry, crop=True)\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": out_image.shape[1],\n",
    "                    \"width\": out_image.shape[2],\n",
    "                    \"transform\": out_transform})\n",
    "\n",
    "    with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name_New + \"\\\\NIRv \" + temp_Distance + \".tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Export those shapefile to local storage for future visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_Distance = ['30m','100m','150m','300m','450m','600m','900m','1350m','1200m','1800m','2500m']\n",
    "list_GDF = [gdf_30m,gdf_100m,gdf_150m,gdf_300m,gdf_450m,gdf_600m,gdf_900m,gdf_1350m,gdf_1200m,gdf_1800m,gdf_2500m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_Distance)):\n",
    "    list_GDF[i].to_file(cwd_Images_Processed + \"\\\\\" + site_Name_New + \"\\\\\" + list_Distance[i] + \".shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### RESAMPLE\n",
    "# from rasterio.enums import Resampling\n",
    "\n",
    "# # Resample 1800m (10m pixel -> 20m pixel)\n",
    "\n",
    "# scale_factor = 0.5\n",
    "\n",
    "# with rasterio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\Nirv 1800m.tif\") as dataset:\n",
    "\n",
    "#     # resample data to target shape\n",
    "#     data = dataset.read(\n",
    "#         out_shape=(\n",
    "#             dataset.count,\n",
    "#             int(dataset.height * scale_factor),\n",
    "#             int(dataset.width * scale_factor)\n",
    "#         ),\n",
    "#         resampling=Resampling.lanczos\n",
    "#     )\n",
    "\n",
    "#     # scale image transform\n",
    "#     transform = dataset.transform * dataset.transform.scale(\n",
    "#         (dataset.width / data.shape[-1]),\n",
    "#         (dataset.height / data.shape[-2])\n",
    "#     )\n",
    "\n",
    "#     out_meta = dataset.meta\n",
    "#     out_meta.update({\n",
    "#         \"height\": data.shape[-2],\n",
    "#         \"width\": data.shape[-1],\n",
    "#         \"transform\": transform\n",
    "#         })\n",
    "\n",
    "#     with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\Nirv 1800m RE.tif\", \"w\", **out_meta) as dest:\n",
    "#         dest.write(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_600m.to_file(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\600m.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_4326.to_file(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\\" + \"site.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DISC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
