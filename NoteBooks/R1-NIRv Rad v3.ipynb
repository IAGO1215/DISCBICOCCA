{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import numpy as np\n",
    "import shapely as shp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import rasterio.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\DISC\"\n",
    "cwd_Images_Raw = cwd + \"\\\\Sentinel-2 Images Raw\"\n",
    "cwd_Images_Processed = cwd + \"\\\\Sentinel-2 Images Processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial homogeneity ROIs\n",
    "distances = [30,100,300,600,900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Site</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Reference network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATGE</td>\n",
       "      <td>52.466778</td>\n",
       "      <td>12.959778</td>\n",
       "      <td>HYPERNET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ATLAS-Mohammed V</td>\n",
       "      <td>33.406152</td>\n",
       "      <td>-5.103319</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ATLAS-Mohammed V New</td>\n",
       "      <td>33.404814</td>\n",
       "      <td>-5.101614</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AT-Mmg</td>\n",
       "      <td>47.316700</td>\n",
       "      <td>10.970300</td>\n",
       "      <td>FLOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BASP</td>\n",
       "      <td>39.049139</td>\n",
       "      <td>-2.075917</td>\n",
       "      <td>HYPERNET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number                  Site   Latitude  Longitude Reference network\n",
       "0       1                  ATGE  52.466778  12.959778          HYPERNET\n",
       "1       2      ATLAS-Mohammed V  33.406152  -5.103319             Other\n",
       "2       3  ATLAS-Mohammed V New  33.404814  -5.101614             Other\n",
       "3       4                AT-Mmg  47.316700  10.970300              FLOX\n",
       "4       5                  BASP  39.049139  -2.075917          HYPERNET"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Site = pd.read_excel(cwd + \"\\\\Site - With Moved ROI (Coordinates Only).xlsx\")\n",
    "df_Site.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real work begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWUK starts!\n",
      "WWUK finished!\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_Site.shape[0]):\n",
    "    site_Name = df_Site[\"Site\"][i]\n",
    "    print(f\"{site_Name} starts!\")\n",
    "    site_Lat = df_Site.loc[i,\"Latitude\"]\n",
    "    site_Lon = df_Site.loc[i,\"Longitude\"]\n",
    "    if site_Name[-3:] != 'New':\n",
    "        # Find the paths to images and metadata .xml files\n",
    "        # L1C B08\n",
    "        for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "            for name in files:\n",
    "                temp = os.path.join(path, name)\n",
    "                if \"IMG_DATA\" in temp and temp[-3:] == 'jp2' and \"B08\" in temp:\n",
    "                    path_L1C_B08_raw = temp\n",
    "        # L1C metadata MTD_DS.xml\n",
    "        for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "            for name in files:\n",
    "                temp = os.path.join(path, name)\n",
    "                if \"MTD_DS.xml\" in temp:\n",
    "                    path_L1C_xml_DS = temp\n",
    "        # L1C metadata MTD_TL.xml\n",
    "        for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "            for name in files:\n",
    "                temp = os.path.join(path, name)\n",
    "                if \"MTD_TL.xml\" in temp:\n",
    "                    path_L1C_xml_TL = temp\n",
    "        # L2A B04 & B08\n",
    "        for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "            for name in files:\n",
    "                temp = os.path.join(path, name)\n",
    "                if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B04\" in temp :\n",
    "                    path_L2A_B04_raw = temp\n",
    "                if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B08\" in temp :\n",
    "                    path_L2A_B08_raw = temp\n",
    "        # L2A metadata MTD_DS.xml\n",
    "        for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "            for name in files:\n",
    "                temp = os.path.join(path, name)\n",
    "                if \"MTD_DS.xml\" in temp:\n",
    "                    # print(temp)\n",
    "                    path_L2A_xml_DS = temp\n",
    "\n",
    "        # Read raster images\n",
    "        image_L1C_B08 = rio.open(path_L1C_B08_raw)\n",
    "        image_L2A_B04 = rio.open(path_L2A_B04_raw)\n",
    "        image_L2A_B08 = rio.open(path_L2A_B08_raw)\n",
    "        values_L1C_B08 = image_L1C_B08.read(1)\n",
    "        values_L2A_B04 = image_L2A_B04.read(1)\n",
    "        values_L2A_B08 = image_L2A_B08.read(1)\n",
    "        crs_L1C = image_L1C_B08.crs.data[\"init\"].split(\":\")[1]\n",
    "        crs_L2A = image_L2A_B04.crs.data[\"init\"].split(\":\")[1]\n",
    "\n",
    "        # Parse metadata .xml files\n",
    "        # Read the DS xml file of L2A\n",
    "        with open(path_L2A_xml_DS, 'r') as f:\n",
    "            data = f.read()\n",
    "        BS_L2A_dS = BeautifulSoup(data, \"xml\")\n",
    "        # Get the quantification value! \n",
    "        quantification_L2A = int(BS_L2A_dS.find(\"BOA_QUANTIFICATION_VALUE\").text)\n",
    "        # Get the radiometric offset!\n",
    "        offset_L2A_B04 = int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"3\"}).text)\n",
    "        offset_L2A_B08 = int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"7\"}).text)\n",
    "        # Read the DS xml file of L1C\n",
    "        with open(path_L1C_xml_DS, 'r') as f:\n",
    "            data = f.read()\n",
    "        BS_L1C_dS = BeautifulSoup(data, \"xml\")\n",
    "        # Get the quantification value! \n",
    "        quantification_L1C = int(BS_L1C_dS.find(\"QUANTIFICATION_VALUE\").text)\n",
    "        # Get the radiometric offset!\n",
    "        offset_L1C = int(BS_L1C_dS.find(\"RADIO_ADD_OFFSET\", {\"band_id\": \"7\"}).text)\n",
    "        # Get the U\n",
    "        U_L1C = float(BS_L1C_dS.find(\"U\").text)\n",
    "        # Get the solar irradiance\n",
    "        SolarIrr = float(BS_L1C_dS.find(\"SOLAR_IRRADIANCE\", {\"bandId\": \"7\"}).text)\n",
    "        # Read the TL xml file of L1C\n",
    "        with open(path_L1C_xml_TL, 'r') as f:\n",
    "            data = f.read()\n",
    "        BS_L1C_dS = BeautifulSoup(data, \"xml\")\n",
    "        # Get the sun zenith angle! There should be a 23 x 23 arrays in the xml. Now we save each row as an array and keep all these arrays into a list\n",
    "        list_SunZenith = []\n",
    "        for row in BS_L1C_dS.find(\"Sun_Angles_Grid\").find(\"Zenith\").find_all(\"VALUES\"):\n",
    "            temp_List = row.text.split(\" \")\n",
    "            temp_Arr = np.array(temp_List)\n",
    "            temp_Arr = temp_Arr.astype(float)\n",
    "            list_SunZenith.append(temp_Arr)\n",
    "        # Now we stack these nested-in-list arrays into a 2d array\n",
    "        index = 0\n",
    "        for arr in list_SunZenith:\n",
    "            if index == 0:\n",
    "                arr_SunZenith = arr\n",
    "            else:\n",
    "                arr_SunZenith = np.vstack((arr_SunZenith, arr))\n",
    "            index = index + 1\n",
    "        # Get the shape of L1C image, which should be (10980, 10980)\n",
    "        shape_L1C = values_L1C_B08.shape\n",
    "        # Repeat each element of sun zenith angle array, in both axies. The final array should have a shape of (11500, 11500)\n",
    "        arr_SunZenith_Repeat = np.repeat(arr_SunZenith, 500, axis = 1)\n",
    "        arr_SunZenith_Repeat = np.repeat(arr_SunZenith_Repeat, 500, axis = 0)\n",
    "        # Index only the first 10980 of each dimension\n",
    "        arr_SunZenith_Assigned = arr_SunZenith_Repeat[0:shape_L1C[0], 0:shape_L1C[1]]\n",
    "\n",
    "        # Calculate NDVI\n",
    "        NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
    "        src = image_L2A_B04\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"dtype\": 'float64'\n",
    "        })\n",
    "        with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NDVI.tif\", 'w', **out_meta) as dest:\n",
    "            dest.write(NDVI, 1)\n",
    "\n",
    "        # Calculate radiance of B8 of L1C\n",
    "        # radiance = reflectance * cos(radians(SunZenithAngle)) * solarIrradiance * U / pi\n",
    "        radiance = (values_L1C_B08 + offset_L1C).astype(float)  * np.cos(np.radians(arr_SunZenith_Assigned)) * SolarIrr / quantification_L1C / (math.pi * (1 / U_L1C))\n",
    "        NIRv = NDVI * radiance\n",
    "        src = image_L1C_B08\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"dtype\": 'float64'\n",
    "        })\n",
    "        with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\", 'w', **out_meta) as dest:\n",
    "            dest.write(NIRv, 1)\n",
    "        \n",
    "        # Re-open NIRv.tif for clipping\n",
    "        src = rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\")\n",
    "        print(f\"Calculation of NDVI and NIRv of site {site_Name} finished!\")\n",
    "    else:\n",
    "        # If a site is a moved ROI, then we directly open the NIRv.tif of original site!\n",
    "        src = rio.open(cwd_Images_Processed + \"\\\\\" + site_Name[:-4] + \"\\\\NIRv.tif\")\n",
    "        print(f\"Original NIRv of site {site_Name} has been read!\")\n",
    "\n",
    "    # Read shapefiles!\n",
    "    list_GDF = []\n",
    "    for distance in distances:\n",
    "        temp_gdf = gpd.read_file(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\\" + str(distance) + \"m.shp\")\n",
    "        list_GDF.append(temp_gdf)\n",
    "    \n",
    "    for index in range(len(list_GDF)):\n",
    "        temp_Distance = distances[index]\n",
    "        temp_GDF = list_GDF[index]\n",
    "        out_image, out_transform = rio.mask.mask(src, temp_GDF.geometry, crop=True)\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform})\n",
    "\n",
    "        with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv \" + str(temp_Distance) + \".tif\", \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "    print(site_Name + \" finished!\")\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DISC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
