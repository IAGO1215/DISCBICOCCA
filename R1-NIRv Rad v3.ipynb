{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import numpy as np\n",
    "import shapely as shp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import rasterio.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = \"c:\\\\Users\\\\m1865\\\\Desktop\\\\DISC\"\n",
    "cwd_Images_Raw = cwd + \"\\\\Sentinel-2 Images Raw\"\n",
    "cwd_Images_Processed = cwd + \"\\\\Sentinel-2 Images Processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Site</th>\n",
       "      <th>Serial Number (FLOX)</th>\n",
       "      <th>Country</th>\n",
       "      <th>Location</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Plant functional type (PFT)</th>\n",
       "      <th>Reference network</th>\n",
       "      <th>Number of components</th>\n",
       "      <th>Reduce ROI size (600 x 600 m)</th>\n",
       "      <th>Move ROI</th>\n",
       "      <th>Comments</th>\n",
       "      <th>PRISMA Availability (900m Buffer ROI Check)</th>\n",
       "      <th>PRISMA Earliest Date</th>\n",
       "      <th>PRISMA Latest Date (Before 2024-06-26)</th>\n",
       "      <th>Tomi</th>\n",
       "      <th>S2 Cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.466778</td>\n",
       "      <td>12.959778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYPERNET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>2023-08-14</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ATLAS-Mohammed V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>ATLAS-Mohammed V</td>\n",
       "      <td>33.406152</td>\n",
       "      <td>-5.103319</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>mixed pixel, complex topography</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AU-MIEMING</td>\n",
       "      <td>JB-042-GW</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Austria</td>\n",
       "      <td>47.316700</td>\n",
       "      <td>10.970300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>topography?</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BASP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.049139</td>\n",
       "      <td>-2.075917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYPERNET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BE-BRASCHAAT</td>\n",
       "      <td>JB-021-SW</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Brasschaat</td>\n",
       "      <td>51.307600</td>\n",
       "      <td>4.519900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FLOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Check the site with Sentinal 3</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number              Site Serial Number (FLOX)  Country          Location  \\\n",
       "0       1              ATGE                  NaN      NaN               NaN   \n",
       "1       2  ATLAS-Mohammed V                  NaN  Morocco  ATLAS-Mohammed V   \n",
       "2       3        AU-MIEMING            JB-042-GW  Austria           Austria   \n",
       "3       4              BASP                  NaN      NaN               NaN   \n",
       "4       5      BE-BRASCHAAT            JB-021-SW  Belgium        Brasschaat   \n",
       "\n",
       "    Latitude  Longitude Priority Plant functional type (PFT)  \\\n",
       "0  52.466778  12.959778      NaN                         NaN   \n",
       "1  33.406152  -5.103319      Low                         NaN   \n",
       "2  47.316700  10.970300      NaN                         NaN   \n",
       "3  39.049139  -2.075917      NaN                         NaN   \n",
       "4  51.307600   4.519900      NaN                         NaN   \n",
       "\n",
       "  Reference network  Number of components Reduce ROI size (600 x 600 m)  \\\n",
       "0          HYPERNET                   NaN                           NaN   \n",
       "1               NaN                   NaN                           Yes   \n",
       "2              FLOX                   NaN                            No   \n",
       "3          HYPERNET                   NaN                           NaN   \n",
       "4              FLOX                   NaN                            No   \n",
       "\n",
       "  Move ROI                         Comments  \\\n",
       "0      NaN                              NaN   \n",
       "1      Yes  mixed pixel, complex topography   \n",
       "2       No                      topography?   \n",
       "3      NaN                              NaN   \n",
       "4       No   Check the site with Sentinal 3   \n",
       "\n",
       "   PRISMA Availability (900m Buffer ROI Check) PRISMA Earliest Date  \\\n",
       "0                                            2           2022-05-06   \n",
       "1                                            2           2023-11-23   \n",
       "2                                            0                  NaN   \n",
       "3                                           27           2022-05-09   \n",
       "4                                            7           2020-09-12   \n",
       "\n",
       "  PRISMA Latest Date (Before 2024-06-26)       Tomi S2 Cloud  \n",
       "0                             2023-08-14          Y      NaN  \n",
       "1                             2023-11-23        NaN      NaN  \n",
       "2                                    NaN  Duplicate      NaN  \n",
       "3                             2024-06-18          Y      NaN  \n",
       "4                             2022-06-01        NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Site = pd.read_csv(cwd + \"//Site.csv\")\n",
    "df_Site.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP-VAL finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVALBARD finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW-DAVOS finished!\n",
      "SWEDEN ICOS finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW-LAG finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW-OTT finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW-PYN finished!\n",
      "Tapajos KM67 Mature Forest site finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK-1 finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK-2 finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK-Amo finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: invalid value encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US ALASKA 1 finished!\n",
      "US ALASKA 2 finished!\n",
      "US-Konza finished!\n",
      "US-LIN finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-OPE finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-SERC finished!\n",
      "Utqiagvik finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m1865\\AppData\\Local\\Temp\\ipykernel_27360\\235916105.py:216: RuntimeWarning: divide by zero encountered in divide\n",
      "  NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWUK finished!\n"
     ]
    }
   ],
   "source": [
    "for i in range(65,df_Site.shape[0]):\n",
    "    site_Name = df_Site[\"Site\"][i]\n",
    "    site_Lat = df_Site.loc[i,\"Latitude\"]\n",
    "    site_Lon = df_Site.loc[i,\"Longitude\"]\n",
    "    if df_Site.loc[i,\"Reduce ROI size (600 x 600 m)\"] == \"Yes\":\n",
    "        site_Reduced = True\n",
    "    else:\n",
    "        site_Reduced = False\n",
    "    df_4326 = pd.DataFrame({\n",
    "        \"Site\": [site_Name],\n",
    "        \"Latitude\": [site_Lat],\n",
    "        \"Longitude\": [site_Lon]\n",
    "    })\n",
    "    # Create a point shapefile based on the site, using Lon-Lat\n",
    "    gdf_4326 = gpd.GeoDataFrame(\n",
    "        df_4326,\n",
    "        geometry = gpd.points_from_xy(df_4326['Longitude'], df_4326['Latitude']),\n",
    "        crs = \"EPSG:4326\"\n",
    "    )\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"IMG_DATA\" in temp and temp[-3:] == 'jp2' and \"B08\" in temp:\n",
    "                # print(temp)\n",
    "                path_L1C_B08_raw = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"MTD_DS.xml\" in temp:\n",
    "                # print(temp)\n",
    "                path_L1C_xml_DS = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L1C\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"MTD_TL.xml\" in temp:\n",
    "                # print(temp)\n",
    "                path_L1C_xml_TL = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B04\" in temp :\n",
    "                path_L2A_B04_raw = temp\n",
    "            if temp[-3:] == 'jp2'in temp and \"10m\" in temp and \"B08\" in temp :\n",
    "                path_L2A_B08_raw = temp\n",
    "    for path, subdirs, files in os.walk(cwd_Images_Raw + \"\\\\\" + site_Name + \"\\\\L2A\"):\n",
    "        for name in files:\n",
    "            temp = os.path.join(path, name)\n",
    "            if \"MTD_DS.xml\" in temp:\n",
    "                # print(temp)\n",
    "                path_L2A_xml_DS = temp\n",
    "    image_L1C_B08 = rio.open(path_L1C_B08_raw)\n",
    "    image_L2A_B04 = rio.open(path_L2A_B04_raw)\n",
    "    image_L2A_B08 = rio.open(path_L2A_B08_raw)\n",
    "    values_L1C_B08 = image_L1C_B08.read(1)\n",
    "    values_L2A_B04 = image_L2A_B04.read(1)\n",
    "    values_L2A_B08 = image_L2A_B08.read(1)\n",
    "    crs_L1C = image_L1C_B08.crs.data[\"init\"].split(\":\")[1]\n",
    "    crs_L2A = image_L2A_B04.crs.data[\"init\"].split(\":\")[1]\n",
    "    # print(\"The EPSG of L1C is \" + crs_L1C)\n",
    "    # print(\"The EPSG of L2A is \" + crs_L2A)\n",
    "    # In the case that L1C and L2A have different crs, give an error. But this shouldn't happen. \n",
    "    if crs_L2A != crs_L1C:\n",
    "        raise SystemExit(\"Stop right there!\")\n",
    "    crs_Final = 'EPSG:' + crs_L1C\n",
    "    gdf_New = gdf_4326.copy()\n",
    "    gdf_New = gdf_New.to_crs(crs_Final)\n",
    "    site_x = gdf_New.geometry.x.values[0]\n",
    "    site_y = gdf_New.geometry.y.values[0]\n",
    "    site_row, site_col = image_L2A_B08.index(site_x, site_y)\n",
    "    site_pixel_x, site_pixel_y = image_L2A_B08.xy(site_row, site_col)\n",
    "    # Get the coordinates of the four corners\n",
    "    # 10m\n",
    "    site_x_left_10m = site_pixel_x - 5\n",
    "    site_x_right_10m = site_pixel_x + 5\n",
    "    site_y_top_10m = site_pixel_y + 5\n",
    "    site_y_bottom_10m = site_pixel_y - 5\n",
    "    # 30m\n",
    "    site_x_left_30m = site_pixel_x - 15\n",
    "    site_x_right_30m = site_pixel_x + 15\n",
    "    site_y_top_30m = site_pixel_y + 15\n",
    "    site_y_bottom_30m = site_pixel_y - 15\n",
    "    # 100m\n",
    "    site_x_left_100m = site_pixel_x - 55\n",
    "    site_x_right_100m = site_pixel_x + 55\n",
    "    site_y_top_100m = site_pixel_y + 55\n",
    "    site_y_bottom_100m = site_pixel_y - 55\n",
    "    # 100 * 1.5 = 150m\n",
    "    site_x_left_150m = site_pixel_x - 75\n",
    "    site_x_right_150m = site_pixel_x + 75\n",
    "    site_y_top_150m = site_pixel_y + 75\n",
    "    site_y_bottom_150m = site_pixel_y - 75\n",
    "    # 300m\n",
    "    site_x_left_300m = site_pixel_x - 155\n",
    "    site_x_right_300m = site_pixel_x + 155\n",
    "    site_y_top_300m = site_pixel_y + 155\n",
    "    site_y_bottom_300m = site_pixel_y - 155\n",
    "    # 300 * 1.5 = 450m\n",
    "    site_x_left_450m = site_pixel_x - 225\n",
    "    site_x_right_450m = site_pixel_x + 225\n",
    "    site_y_top_450m = site_pixel_y + 225\n",
    "    site_y_bottom_450m = site_pixel_y - 225\n",
    "    if site_Reduced:\n",
    "        # 600m\n",
    "        site_x_left_600m = site_pixel_x - 305\n",
    "        site_x_right_600m = site_pixel_x + 305\n",
    "        site_y_top_600m = site_pixel_y + 305\n",
    "        site_y_bottom_600m = site_pixel_y - 305\n",
    "    # 900m\n",
    "    site_x_left_900m = site_pixel_x - 455\n",
    "    site_x_right_900m = site_pixel_x + 455\n",
    "    site_y_top_900m = site_pixel_y + 455\n",
    "    site_y_bottom_900m = site_pixel_y - 455\n",
    "    # 900 * 1.5 = 1350m\n",
    "    site_x_left_1350m = site_pixel_x - 675\n",
    "    site_x_right_1350m = site_pixel_x + 675\n",
    "    site_y_top_1350m = site_pixel_y + 675\n",
    "    site_y_bottom_1350m = site_pixel_y - 675\n",
    "    # 1200m\n",
    "    site_x_left_1200m = site_pixel_x - 605\n",
    "    site_x_right_1200m = site_pixel_x + 605\n",
    "    site_y_top_1200m = site_pixel_y + 605\n",
    "    site_y_bottom_1200m = site_pixel_y - 605\n",
    "    # 1800m\n",
    "    site_x_left_1800m = site_pixel_x - 905\n",
    "    site_x_right_1800m = site_pixel_x + 905\n",
    "    site_y_top_1800m = site_pixel_y + 905\n",
    "    site_y_bottom_1800m = site_pixel_y - 905\n",
    "    # 2500m\n",
    "    site_x_left_2500m = site_pixel_x - 1255\n",
    "    site_x_right_2500m = site_pixel_x + 1255\n",
    "    site_y_top_2500m = site_pixel_y + 1255\n",
    "    site_y_bottom_2500m = site_pixel_y - 1255\n",
    "    # Now we need to form squares shapefile, which will be the internal area of which we will evaluate the spatial representativeness. \n",
    "    shp_10m = shp.box(site_x_left_10m, site_y_bottom_10m, site_x_right_10m, site_y_top_10m)\n",
    "    gdf_10m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_10m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_30m = shp.box(site_x_left_30m, site_y_bottom_30m, site_x_right_30m, site_y_top_30m)\n",
    "    gdf_30m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_30m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_100m = shp.box(site_x_left_100m, site_y_bottom_100m, site_x_right_100m, site_y_top_100m)\n",
    "    gdf_100m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_100m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_150m = shp.box(site_x_left_150m, site_y_bottom_150m, site_x_right_150m, site_y_top_150m)\n",
    "    gdf_150m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_150m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_300m = shp.box(site_x_left_300m, site_y_bottom_300m, site_x_right_300m, site_y_top_300m)\n",
    "    gdf_300m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_300m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_450m = shp.box(site_x_left_450m, site_y_bottom_450m, site_x_right_450m, site_y_top_450m)\n",
    "    gdf_450m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_450m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    if site_Reduced:\n",
    "        shp_600m = shp.box(site_x_left_600m, site_y_bottom_600m, site_x_right_600m, site_y_top_600m)\n",
    "        gdf_600m = gpd.GeoDataFrame(\n",
    "            pd.DataFrame({\"0\": [\"0\"]}),\n",
    "            geometry=[shp_600m],\n",
    "            crs = crs_Final\n",
    "        )\n",
    "    shp_900m = shp.box(site_x_left_900m, site_y_bottom_900m, site_x_right_900m, site_y_top_900m)\n",
    "    gdf_900m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_900m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_1350m = shp.box(site_x_left_1350m, site_y_bottom_1350m, site_x_right_1350m, site_y_top_1350m)\n",
    "    gdf_1350m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_1350m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_1200m = shp.box(site_x_left_1200m, site_y_bottom_1200m, site_x_right_1200m, site_y_top_1200m)\n",
    "    gdf_1200m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_1200m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_1800m = shp.box(site_x_left_1800m, site_y_bottom_1800m, site_x_right_1800m, site_y_top_1800m)\n",
    "    gdf_1800m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_1800m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    shp_2500m = shp.box(site_x_left_2500m, site_y_bottom_2500m, site_x_right_2500m, site_y_top_2500m)\n",
    "    gdf_2500m = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"0\": [\"0\"]}),\n",
    "        geometry=[shp_2500m],\n",
    "        crs = crs_Final\n",
    "    )\n",
    "    # Read the DS xml file of L2A\n",
    "    with open(path_L2A_xml_DS, 'r') as f:\n",
    "        data = f.read()\n",
    "    BS_L2A_dS = BeautifulSoup(data, \"xml\")\n",
    "    # Get the quantification value! \n",
    "    quantification_L2A = int(BS_L2A_dS.find(\"BOA_QUANTIFICATION_VALUE\").text)\n",
    "    # Get the radiometric offset!\n",
    "    offset_L2A_B04 = int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"3\"}).text)\n",
    "    offset_L2A_B08 = int(BS_L2A_dS.find(\"BOA_ADD_OFFSET\", {\"band_id\": \"7\"}).text)\n",
    "    NDVI = ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A - (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A) / ((values_L2A_B08 + offset_L2A_B08).astype(float) / quantification_L2A + (values_L2A_B04 + offset_L2A_B04).astype(float) / quantification_L2A )\n",
    "    src = image_L2A_B04\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"dtype\": 'float64'\n",
    "    })\n",
    "    with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NDVI.tif\", 'w', **out_meta) as dest:\n",
    "        dest.write(NDVI, 1)\n",
    "    # Read the DS xml file of L1C\n",
    "    with open(path_L1C_xml_DS, 'r') as f:\n",
    "        data = f.read()\n",
    "    BS_L1C_dS = BeautifulSoup(data, \"xml\")\n",
    "    # Get the quantification value! \n",
    "    quantification_L1C = int(BS_L1C_dS.find(\"QUANTIFICATION_VALUE\").text)\n",
    "    # Get the radiometric offset!\n",
    "    offset_L1C = int(BS_L1C_dS.find(\"RADIO_ADD_OFFSET\", {\"band_id\": \"7\"}).text)\n",
    "    # Get the U\n",
    "    U_L1C = float(BS_L1C_dS.find(\"U\").text)\n",
    "    # Get the solar irradiance\n",
    "    SolarIrr = float(BS_L1C_dS.find(\"SOLAR_IRRADIANCE\", {\"bandId\": \"7\"}).text)\n",
    "    # Read the TL xml file of L1C\n",
    "    with open(path_L1C_xml_TL, 'r') as f:\n",
    "        data = f.read()\n",
    "    BS_L1C_dS = BeautifulSoup(data, \"xml\")\n",
    "    # Get the sun zenith angle! There should be a 23 x 23 arrays in the xml. Now we save each row as an array and keep all these arrays into a list\n",
    "    list_SunZenith = []\n",
    "    for row in BS_L1C_dS.find(\"Sun_Angles_Grid\").find(\"Zenith\").find_all(\"VALUES\"):\n",
    "        temp_List = row.text.split(\" \")\n",
    "        temp_Arr = np.array(temp_List)\n",
    "        temp_Arr = temp_Arr.astype(float)\n",
    "        list_SunZenith.append(temp_Arr)\n",
    "    # Now we stack these nested-in-list arrays into a 2d array\n",
    "    index = 0\n",
    "    for arr in list_SunZenith:\n",
    "        if index == 0:\n",
    "            arr_SunZenith = arr\n",
    "        else:\n",
    "            arr_SunZenith = np.vstack((arr_SunZenith, arr))\n",
    "        index = index + 1\n",
    "    # Get the shape of L1C image, which should be (10980, 10980)\n",
    "    shape_L1C = values_L1C_B08.shape\n",
    "    # Repeat each element of sun zenith angle array, in both axies. The final array should have a shape of (11500, 11500)\n",
    "    arr_SunZenith_Repeat = np.repeat(arr_SunZenith, 500, axis = 1)\n",
    "    arr_SunZenith_Repeat = np.repeat(arr_SunZenith_Repeat, 500, axis = 0)\n",
    "    # Index only the first 10980 of each dimension\n",
    "    arr_SunZenith_Assigned = arr_SunZenith_Repeat[0:shape_L1C[0], 0:shape_L1C[1]]\n",
    "    # radiance = reflectance * cos(radians(SunZenithAngle)) * solarIrradiance * U / pi\n",
    "    radiance = (values_L1C_B08 + offset_L1C).astype(float)  * np.cos(np.radians(arr_SunZenith_Assigned)) * SolarIrr / quantification_L1C / (math.pi * (1 / U_L1C))\n",
    "    NIRv = NDVI * radiance\n",
    "    src = image_L1C_B08\n",
    "    out_meta = src.meta\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"dtype\": 'float64'\n",
    "    })\n",
    "    with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\", 'w', **out_meta) as dest:\n",
    "        dest.write(NIRv, 1)\n",
    "    list_Distance = ['10m','30m','100m','150m','300m','450m','900m','1350m','1200m','1800m','2500m']\n",
    "    list_GDF = [gdf_10m,gdf_30m,gdf_100m,gdf_150m,gdf_300m,gdf_450m,gdf_900m,gdf_1350m,gdf_1200m,gdf_1800m,gdf_2500m]\n",
    "    for index in range(len(list_Distance)):\n",
    "        temp_Distance = list_Distance[index]\n",
    "        temp_GDF = list_GDF[index]\n",
    "        src = rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\")\n",
    "        out_image, out_transform = rio.mask.mask(src, temp_GDF.geometry, crop=True)\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform})\n",
    "\n",
    "        with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv \" + temp_Distance + \".tif\", \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "    for i in range(len(list_Distance)):\n",
    "        list_GDF[i].to_file(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\\" + list_Distance[i] + \".shp\")\n",
    "    if site_Reduced:\n",
    "        src = rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv.tif\")\n",
    "        out_image, out_transform = rio.mask.mask(src, gdf_600m.geometry, crop=True)\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        \"transform\": out_transform})\n",
    "\n",
    "        with rio.open(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\NIRv 600m.tif\", \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "        gdf_600m.to_file(cwd_Images_Processed + \"\\\\\" + site_Name + \"\\\\600m.shp\")\n",
    "    print(site_Name + \" finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DISC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
